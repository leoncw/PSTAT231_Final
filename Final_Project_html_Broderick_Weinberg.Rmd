---
title: "PSTAT 231 Final Broderick-Weinberg"
author: "Hailey Broderick and Callum Weinberg"
date: "March 11, 2022"
output:
  html_document:
    code_folding: show
  html_notebook:
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# This is necessary given the nested directories.
# Enter your working directory here
knitr::opts_knit$set(root.dir = "/home/clw/Documents/UCSB/Quarter6/PSTAT 231/Final Project/PSTAT231_Final")
```


# Executive Summary

# Introduction

[Make reference early to the github page where this is hosted]

## Background

## Data

[DISCUSSION OF WHICH FOLDERS, CSVS, and VARIABLES are kept]

[CITE Kaggle and world bank]

## Purpose and Methods

# Libraries

```{r libraries, message=FALSE}
library(knitr)
library(plyr)
library(dplyr)
library(tidyr)
library(assertr)
library(ggplot2)
library(reshape2)
```

# Functions

```{r functions}
# From https://cran.r-project.org/web/packages/assertr/vignettes/assertr.html
not.missing.p <- function(x) if(is.na(x)) return(FALSE)


# Define Median Replacement function (for a matrix)
# Used for data interpolation
median_replace = function(x) {
  for(i in 1:ncol(x)) {
    # Note: this will break if an entire column is missing values
    x[which(is.na(x[,i])),i] = median(x[,i],na.rm=TRUE)
  }
  return(x)
}
```

# Data Cleaning

## Manual Crosswalks

As mentioned above, within each folder from the Kaggle dataset, the differnt CSV files sometimes had the countries indexed to different values. In other words, there was not a unique identifier between the different CSV files for the Energy and Mineral folder and the Land and Agrigulture folder. In order to combine (merge) these datasets, manual "crosswalks" had to be compiled, with a new identifier variable generated. These crosswalk files are available in the "Crosswalks" folder in the both the submission (note this applies to the submission for PSTAT 231) and the hosted github page (see introduction).

Additionally, there is a "final crosswalk" which maps the different subfolders (after the CSV from each sub folder has been combined) together is loaded.

```{r load_manual_crosswalks, class.source = 'fold-hide', echo = TRUE, results='hide'}
## Energy and Minerals Crosswalk
energy_minerals_crosswalk_manual = read.csv("Crosswalks/Energy_Minerals_Crosswalk.csv")
energy_minerals_crosswalk_mineral_manual = read.csv("Crosswalks/Energy_Minerals_Crosswalk_mineral_dataset.csv")

## Land and Agriculture Crosswalks
land_agriculture_preliminary_manual = read.csv("Crosswalks/land_agricultural_preliminary.csv")
land_agriculture_final_manual = read.csv("Crosswalks/land_agricultural_final.csv")

## Final Crosswalk for Mapping Categories
## Includes World Bank Data
final_crosswalk = read.csv("Crosswalks/02_final_crosswalk.csv")
final_crosswalk = final_crosswalk %>%
  rename(Country = Country_Mapping)
# Get version with only Country and ID
final_crosswalk_Country_Only = final_crosswalk %>%
  select(Country, Country_ID_Final)
```

## Loading and Combing CSVs from Subfolders

The CSVs from each subfolder are loaded and cleaned. Cleaning in this case refers to keeping variables of interest, renaming variables, dropping empty rows, and checking that Country and Country ID are unique. For the folders that do have a unique country identifier for all CSVs in the folder, a crosswalk is generated in R and the CSVs are merged using that. Versions of the merged data are saved to the "intermediate" folder - this was done mainly to create the "final crosswalk" and is not strictly necessary if this code is being rerun.

The world bank data variables are included in the final crosswalk: they were manually entered into the CSV.

Air and Climate Code:

```{r air_and_climate, class.source = 'fold-hide', echo = TRUE, results='hide'}
## CH_4 Emissions
CH4_emissions = read.csv("Raw_Data/Air and Climate/CH4_Emissions.csv")

CH4_emissions = CH4_emissions %>%
  rename(Country_ID = Country.ID,
         CH4_latest_year = X.28, 
         CH4 = CH4.emissions..latest.year, 
         CH4_change_1990 = X..change.since.1990, 
         CH4_per_capita = CH4.emissions..per.capita...latest.year) %>%
  select(Country_ID,Country,CH4_latest_year,CH4,CH4_change_1990,CH4_per_capita) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)

## CO2 Emissions
CO2_emissions = read.csv("Raw_Data/Air and Climate/CO2_Emissions.csv")

CO2_emissions = CO2_emissions %>%
  rename(Country_ID = Country.ID,
         CO2_latest_year = X.28, 
         CO2 = CO2.emissions..latest.year, 
         CO2_change_1990 = X..change.since.1990, 
         CO2_per_capita = CO2.emissions..per.capita...latest.year) %>%
  select(Country_ID,Country,CO2_latest_year,CO2,CO2_change_1990,CO2_per_capita) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)

## GHG Emissions
GHG_emissions = read.csv("Raw_Data/Air and Climate/GHG_Emissions.csv")

GHG_emissions = GHG_emissions %>%
  rename(Country_ID = Country.ID,
         GHG_latest_year = X.28, 
         GHG = GHG.total.without.LULUCF..latest.year, 
         GHG_change_1990 = X..change.since.1990, 
         GHG_per_capita = GHG.emissions.per.capita...latest.year) %>%
  select(Country_ID,Country,GHG_latest_year,GHG,GHG_change_1990,GHG_per_capita) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)

## GHG Emissions
GHG_emissions = read.csv("Raw_Data/Air and Climate/GHG_Emissions.csv")
# GHG_sector_total should be the same as GHG, if not investigate

GHG_emissions = GHG_emissions %>%
  rename(Country_ID = Country.ID,
         GHG_latest_year = X.28, 
         GHG = GHG.total.without.LULUCF..latest.year,
         GHG_change_1990 = X..change.since.1990, 
         GHG_per_capita = GHG.emissions.per.capita...latest.year) %>%
  select(Country_ID,Country,GHG_latest_year,GHG,GHG_change_1990,GHG_per_capita) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)

## GHG Emissions by Sector
# Add this in
# GHG_emissions_by_sector = read.csv("Data/Air and Climate/GHG_Emissions_by_Sector.csv")
# GHG_sector_total should be the same as GHG, if not investigate

## N2O Emissions
N2O_emissions = read.csv("Raw_Data/Air and Climate/N2O_Emissions.csv")

N2O_emissions = N2O_emissions %>%
  rename(Country_ID = Country.ID,
         N2O_latest_year = X.28, 
         N2O = N2O.emissions..latest.year, 
         N2O_change_1990 = X..change.since.1990, 
         N2O_per_capita = N2O.emissions..per.capita...latest.year) %>%
  select(Country_ID,Country,N2O_latest_year,N2O,N2O_change_1990,N2O_per_capita) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)

## NOx Emissions
# There are some blank lines in this
# file that need to be skipped
NOx_emissions = read.csv("Raw_Data/Air and Climate/NOx_Emissions.csv")

NOx_emissions = NOx_emissions %>%
  rename(Country_ID = Country.ID,
         NOx_latest_year = X.28, 
         NOx = NOx.emissions..latest.year, 
         NOx_change_1990 = X..change.since.1990, 
         NOx_per_capita = NOx..emissions.per.capita...latest.year) %>%
  select(Country_ID,Country,NOx_latest_year,NOx,NOx_change_1990,NOx_per_capita) %>%
  slice(2:173) %>%
  assert(not.missing.p, Country_ID)

## SO2 Emissions
SO2_emissions = read.csv("Raw_Data/Air and Climate/SO2_emissions.csv")

SO2_emissions = SO2_emissions %>%
  rename(Country_ID = Country.ID,
         SO2_latest_year = X.28, 
         SO2 = SO2.emissions..latest.year, 
         SO2_change_1990 = X..change.since.1990, 
         SO2_per_capita = SO2.emissions.per.capita..latest.year) %>%
  select(Country_ID,Country,SO2_latest_year,SO2,SO2_change_1990,SO2_per_capita) %>%
  slice(2:143) %>%
  assert(not.missing.p, Country_ID)


# Append all of the Datasets
crosswalk_air_climate = rbind.fill(CH4_emissions,
                                   CO2_emissions,
                                   GHG_emissions,
                                   N2O_emissions,
                                   NOx_emissions,
                                   SO2_emissions)

# Create the Crosswalk
crosswalk_air_climate = crosswalk_air_climate %>%
  select(Country_ID, Country) %>%
  distinct()

# Check if there are any Duplicates 
# This would mean that for the air and climate datasets
# there are either repeated countries, IDs, or that
# ID is not unique to country between the datasets
# and Vice versa
dim(crosswalk_air_climate[duplicated(crosswalk_air_climate$Country_ID),])[1] == 0
dim(crosswalk_air_climate[duplicated(crosswalk_air_climate$Country),])[1] == 0

# COmbine the datasets
# Start with the Above Created Crosswalk
# And Merge on Each of the Datasets
combined_air_climate = 
  left_join(crosswalk_air_climate,CH4_emissions, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_air_climate = 
  left_join(combined_air_climate,CO2_emissions, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_air_climate = 
  left_join(combined_air_climate,GHG_emissions, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_air_climate = 
  left_join(combined_air_climate,N2O_emissions, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_air_climate = 
  left_join(combined_air_climate,NOx_emissions, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_air_climate = 
  left_join(combined_air_climate,SO2_emissions, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)

# Export Data
save(combined_air_climate, file="Intermediate_Data/001_combined_air_climate.Rdata")
write.csv(combined_air_climate,"Intermediate_Data/001_combined_air_climate.csv", row.names = FALSE)

# Merge in Final Crosswalk to Get Universal ID
combined_air_climate_clean = 
  left_join(final_crosswalk_Country_Only,combined_air_climate, by = "Country") %>%
  filter(!is.na(Country_ID)) %>%
  select(-Country, -Country_ID) %>%
  filter(Country_ID_Final != 999) #Excluded before merging

# Clean Up Environment
remove(crosswalk_air_climate,combined_air_climate, CH4_emissions, CO2_emissions,
       GHG_emissions,N2O_emissions, NOx_emissions, SO2_emissions)
```

Energy and Minerals Code: 

```{r energy_and_minerals, class.source = 'fold-hide', echo = TRUE, results='hide'}
## Renewable Percentage
# Current problem is to model 2017 renewable energy
# so only keeping 2017 variable in this iteration

# Also there are some empty rows and the end of the
# data set
renewable_percentage = read.csv("Raw_Data/Energy and Minerals/Renewable elec production percentage.csv")

renewable_percentage = renewable_percentage %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area, 
         renewable_percent_2017 = X2017) %>%
  select(Country_ID,renewable_percent_2017) %>%
  slice(1:224) %>%
  assert(not.missing.p, Country_ID) %>%
  left_join(energy_minerals_crosswalk_manual, by = "Country_ID")

## Energy Indicators
# YEAR NOT INDICATED
energy_indicators = read.csv("Raw_Data/Energy and Minerals/Energy Indicators.csv")

energy_indicators = energy_indicators %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area, 
         energy_supply_petajoules = Energy.supply..petajoules.,
         energy_supply_per_capita_gigajoules = Energy.supply..per.capita...gigajoules.per.capita.,
         contribution_renewable_to_electric_production = Conribution.of.renewables.to.electricity.production....) %>%
  select(Country_ID,energy_supply_petajoules,
         energy_supply_per_capita_gigajoules, 
         contribution_renewable_to_electric_production) %>%
  slice(1:217) %>%
  assert(not.missing.p, Country_ID) %>%
  left_join(energy_minerals_crosswalk_manual, by = "Country_ID")

## Energy Intensity
energy_intensity = read.csv("Raw_Data/Energy and Minerals/Energy intensity measured in terms of primary energy and GDP.csv")

energy_intensity = energy_intensity %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area, 
         energy_intensity_2017 = X2017) %>%
  select(Country_ID, energy_intensity_2017) %>%
  assert(not.missing.p, Country_ID) %>%
  left_join(energy_minerals_crosswalk_manual, by = "Country_ID")

## Energy Supply Per Capita
energy_supply_per_capita = read.csv("Raw_Data/Energy and Minerals/Energy supply per capita.csv")

energy_supply_per_capita = energy_supply_per_capita %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area, 
         energy_supply_per_capita_2017 = X2017) %>%
  select(Country_ID,energy_supply_per_capita_2017) %>%
  slice(1:222) %>%
  assert(not.missing.p, Country_ID) %>%
  left_join(energy_minerals_crosswalk_manual, by = "Country_ID")

## Energy Supply
energy_supply = read.csv("Raw_Data/Energy and Minerals/Energy supply.csv")

energy_supply = energy_supply %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area, 
         energy_supply_2017 = X2017) %>%
  select(Country_ID,energy_supply_2017) %>%
  slice(1:222) %>%
  assert(not.missing.p, Country_ID) %>%
  left_join(energy_minerals_crosswalk_manual, by = "Country_ID")

## Contribution of Mining to Value Added
# Only keeping 2017
# Missing ID: will need to fix this
mining_percentage = read.csv("Raw_Data/Energy and Minerals/Contribution of mining to value added.csv")

mining_percentage = mining_percentage %>%
  rename(Country = Country.and.area, 
         mining_value_2017 = X2017) %>%
  select(Country,mining_value_2017) %>%
  assert(not.missing.p, Country) %>%
  left_join(energy_minerals_crosswalk_mineral_manual, 
            by = c("Country" = "Country_Corrected")) %>% # Correct Missing ID
  select(-Country) %>%
  left_join(energy_minerals_crosswalk_manual, by = "Country_ID")

# Append all of the Datasets
crosswalk_energy_minerals = rbind.fill(renewable_percentage,
                                   energy_indicators,
                                   energy_intensity,
                                   energy_supply_per_capita,
                                   energy_supply, 
                                   mining_percentage)

# Create the Crosswalk
crosswalk_energy_minerals = crosswalk_energy_minerals %>%
  select(Country_ID, Country) %>%
  distinct()

#write.csv(crosswalk_energy_minerals,"Crosswalks/Base_Energy_Minerals_Crosswalk.csv", row.names = FALSE)

# Check if there are any Duplicates 
# This would mean that for the energy and minerals datasets
# there are either repeated countries, IDs, or that
# ID is not unique to country between the datasets
# and Vice versa
dim(crosswalk_energy_minerals[duplicated(crosswalk_energy_minerals$Country_ID),])[1] == 0
dim(crosswalk_energy_minerals[duplicated(crosswalk_energy_minerals$Country_Corrected),])[1] == 0

# Combine the CSVs
# Start with the Above Created Crosswalk
# And Merge on Each of the Datasets
combined_energy_minerals = 
  left_join(crosswalk_energy_minerals,renewable_percentage, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_energy_minerals = 
  left_join(combined_energy_minerals,energy_indicators, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_energy_minerals = 
  left_join(combined_energy_minerals,energy_intensity, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_energy_minerals = 
  left_join(combined_energy_minerals,energy_supply_per_capita, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_energy_minerals = 
  left_join(combined_energy_minerals,energy_supply, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_energy_minerals = 
  left_join(combined_energy_minerals,mining_percentage, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)

# Export Data
save(combined_energy_minerals, file="Intermediate_Data/002_combined_energy_minerals.Rdata")
write.csv(combined_energy_minerals,"Intermediate_Data/002_combined_energy_minerals.csv", row.names = FALSE)

# Merge in Final Crosswalk to Get Universal ID
combined_energy_minerals_clean = 
  left_join(final_crosswalk_Country_Only,combined_energy_minerals, by = "Country") %>%
  filter(!is.na(Country_ID)) %>%
  select(-Country, -Country_ID) %>%
  filter(Country_ID_Final != 999) #Excluded before merging

# Clean Up Environment
remove(crosswalk_energy_minerals,combined_energy_minerals,renewable_percentage, energy_indicators,
       energy_intensity,energy_supply_per_capita,energy_supply, mining_percentage,energy_minerals_crosswalk_manual, 
       energy_minerals_crosswalk_mineral_manual)
```


Land and Agriculture Code

```{r land_and_agriculture, class.source = 'fold-hide', echo = TRUE, results='hide'}
## Agricultural Land
agriculture_land = read.csv("Raw_Data/Land and Agriculture/Agricultural Land.csv")

# not including change in cultural land since 1990
# missing a good amount. Also not including
# agricultural land actually irrigated, also 
# missing a lot
agriculture_land = agriculture_land %>%
  rename(Country = Country,
         agricultural_area_2013 = Agricultural.area.in.2013..km2., 
         percent_land_agricultural_2013 = X..of.total.land.area.covered.by.agricultural.area.in.2013, 
         arable_land_2013 = Arable.land.in.2013..km2., 
         permanent_crops_2013 = Permanent.crops.in.2013..km2.,
         permanent_meadows_pastures_2013 = Permanent.meadows.and.pastures.in.2013..km2.) %>%
  select(Country,agricultural_area_2013,percent_land_agricultural_2013,arable_land_2013,
         permanent_crops_2013,permanent_meadows_pastures_2013) %>%
  assert(not.missing.p, Country) %>% # ID missing 
  left_join(land_agriculture_preliminary_manual, by = "Country") %>%
  assert(not.missing.p, Country_ID) %>%
  select(-Country) %>%
  left_join(land_agriculture_final_manual, by = "Country_ID")


## Consumption of Fertilizers Per Unit of 
## Agricultural Land
consumption_fertilizer = read.csv("Raw_Data/Land and Agriculture/Consumption of fertilizers per unit of agricultural land area.csv")

consumption_fertilizer = consumption_fertilizer %>%
  rename(Country = Country,
         nitrogen_consumption = Nitrogen, 
         phosphate_consumption = Phosphate, 
         potash_consumption = Potash) %>%
  select(Country,nitrogen_consumption,phosphate_consumption,potash_consumption) %>%
  assert(not.missing.p, Country) %>% # ID missing 
  left_join(land_agriculture_preliminary_manual, by = "Country") %>%
  assert(not.missing.p, Country_ID) %>%
  select(-Country) %>%
  left_join(land_agriculture_final_manual, by = "Country_ID")

## Terrestrial Protected Areas
# All 2018
terrestrial_protected_areas = read.csv("Raw_Data/Land and Agriculture/Terrestrial protected areas.csv")
  
terrestrial_protected_areas = terrestrial_protected_areas %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area,
         terrestrial_protected_areas = Terrestrial.protected.areas) %>%
  select(Country_ID,Country,terrestrial_protected_areas) %>%
  slice(3:n()) %>%
  assert(not.missing.p, Country_ID) %>%
  select(-Country) %>%
  left_join(land_agriculture_final_manual, by = "Country_ID")

# Append all of the Datasets
crosswalk_land_agricultural = rbind.fill(agriculture_land,
                                   consumption_fertilizer,
                                   terrestrial_protected_areas)

# Create the Crosswalk
crosswalk_land_agricultural = crosswalk_land_agricultural %>%
  select(Country_ID, Country) %>%
  distinct()

# Check if there are any Duplicates 
# This would mean that for the energy and minerals datasets
# there are either repeated countries, IDs, or that
# ID is not unique to country between the datasets
# and Vice versa
dim(crosswalk_land_agricultural[duplicated(crosswalk_land_agricultural$Country_ID),])[1] == 0
dim(crosswalk_land_agricultural[duplicated(crosswalk_land_agricultural$Country_Corrected),])[1] == 0

# Combine the CSVs
# Start with the Above Created Crosswalk
# And Merge on Each of the Datasets
combined_land_agricultural = 
  left_join(crosswalk_land_agricultural,agriculture_land, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_land_agricultural = 
  left_join(combined_land_agricultural,consumption_fertilizer, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_land_agricultural = 
  left_join(combined_land_agricultural,terrestrial_protected_areas, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)

# Export Data
save(combined_land_agricultural, file="Intermediate_Data/003_combined_land_agricultural.Rdata")
write.csv(combined_land_agricultural,"Intermediate_Data/003_combined_land_agricultural.csv", row.names = FALSE)

# Merge in Final Crosswalk to Get Universal ID
combined_land_agricultural_clean = 
  left_join(final_crosswalk_Country_Only,combined_land_agricultural, by = "Country") %>%
  filter(!is.na(Country_ID)) %>%
  select(-Country, -Country_ID) %>%
  filter(Country_ID_Final != 999) #Excluded before merging

# Clean Up Environment
remove(crosswalk_land_agricultural,combined_land_agricultural,agriculture_land, 
       consumption_fertilizer,terrestrial_protected_areas, land_agriculture_preliminary_manual,
       land_agriculture_final_manual)
```

Natural Disaster Code

```{r natural_disaster, class.source = 'fold-hide', echo = TRUE, results='hide'}
## climatological disasters
climatological_disasters = read.csv("Raw_Data/Natural Disasters/Climatological disasters.csv")

climatological_disasters = climatological_disasters %>%
  rename(Country_ID = CountryID,
         Country = Countries.or.areas, 
         climate_disaster_occurence_2010_2019 = Occurrence.2010.2019, 
         climate_disaster_deaths_2010_2019 = Total.deaths.2010.2019, 
         climate_disaster_affected_2010_2019 = Persons.affected.2010.2019) %>%
  select(Country_ID,Country,climate_disaster_occurence_2010_2019,
         climate_disaster_deaths_2010_2019,
         climate_disaster_affected_2010_2019) %>%
  assert(not.missing.p, Country_ID)

## geophysical disasters
geophysical_disasters = read.csv("Raw_Data/Natural Disasters/Geophysical disasters.csv")

geophysical_disasters = geophysical_disasters %>%
  rename(Country_ID = CountryID,
         Country = Countries.or.areas, 
         geophysical_disaster_occurence_2010_2019 = Occurrence.2010.2019, 
         geophysical_disaster_deaths_2010_2019 = Total.deaths.2010.2019, 
         geophysical_disaster_affected_2010_2019 = Persons.affected.2010.2019) %>%
  select(Country_ID,Country,geophysical_disaster_occurence_2010_2019,
         geophysical_disaster_deaths_2010_2019,
         geophysical_disaster_affected_2010_2019) %>%
  assert(not.missing.p, Country_ID)


## hydrological disasters
hydrological_disasters = read.csv("Raw_Data/Natural Disasters/Hydrological disasters.csv")

hydrological_disasters = hydrological_disasters %>%
  rename(Country_ID = CountryID,
         Country = Countries.or.areas, 
         hydrological_disaster_occurence_2010_2019 = Occurrence.2010.2019, 
         hydrological_disaster_deaths_2010_2019 = Total.deaths.2010.2019, 
         hydrological_disaster_affected_2010_2019 = Persons.affected.2010.2019) %>%
  select(Country_ID,Country,hydrological_disaster_occurence_2010_2019,
         hydrological_disaster_deaths_2010_2019,
         hydrological_disaster_affected_2010_2019) %>%
  assert(not.missing.p, Country_ID)


## meteorological disasters
meteorological_disasters = read.csv("Raw_Data/Natural Disasters/Meteorological disasters.csv")

meteorological_disasters = meteorological_disasters %>%
  rename(Country_ID = CountryID,
         Country = Countries.or.areas, 
         meteorological_disaster_occurence_2010_2019 = Occurrence.2010.2019, 
         meteorological_disaster_deaths_2010_2019 = Total.deaths.2010.2019, 
         meteorological_disaster_affected_2010_2019 = Persons.affected.2010.2019) %>%
  select(Country_ID,Country,meteorological_disaster_occurence_2010_2019,
         meteorological_disaster_deaths_2010_2019,
         meteorological_disaster_affected_2010_2019) %>%
  assert(not.missing.p, Country_ID)

# Append all of the Datasets
crosswalk_natural_disaster = rbind.fill(climatological_disasters,
                                   geophysical_disasters,
                                   hydrological_disasters,
                                   meteorological_disasters)

# Create the Crosswalk
crosswalk_natural_disaster = crosswalk_natural_disaster %>%
  select(Country_ID, Country) %>%
  distinct()

# Check if there are any Duplicates 
# This would mean that for the energy and minerals datasets
# there are either repeated countries, IDs, or that
# ID is not unique to country between the datasets
# and Vice versa
dim(crosswalk_natural_disaster[duplicated(crosswalk_natural_disaster$Country_ID),])[1] == 0
dim(crosswalk_natural_disaster[duplicated(crosswalk_natural_disaster$Country_Corrected),])[1] == 0

# Combine CSVs
# Start with the Above Created Crosswalk
# And Merge on Each of the Datasets
combined_natural_disaster = 
  left_join(crosswalk_natural_disaster,climatological_disasters, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_natural_disaster = 
  left_join(combined_natural_disaster,geophysical_disasters, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_natural_disaster = 
  left_join(combined_natural_disaster,hydrological_disasters, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_natural_disaster = 
  left_join(combined_natural_disaster,meteorological_disasters, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)

# Export Data
save(combined_natural_disaster, file="Intermediate_Data/004_combined_natural_disaster.Rdata")
write.csv(combined_natural_disaster,"Intermediate_Data/004_combined_natural_disaster.csv", row.names = FALSE)

# Merge in Final Crosswalk to Get Universal ID
combined_natural_disaster_clean = 
  left_join(final_crosswalk_Country_Only,combined_natural_disaster, by = "Country") %>%
  filter(!is.na(Country_ID)) %>%
  select(-Country, -Country_ID) %>%
  filter(Country_ID_Final != 999) #Excluded before merging

# Clean Up Environment
remove(crosswalk_natural_disaster,combined_natural_disaster,climatological_disasters, 
       geophysical_disasters,hydrological_disasters, meteorological_disasters)
```

Other Categories Code:

```{r other_categories, class.source = 'fold-hide', echo = TRUE, results='hide'}
## Biodiversity Data/Marine and Terrestrial Protected areas
# row 1 is world total
protected_areas_marine_terrestrial = read.csv("Raw_Data/Biodiversity/Terrestrial_Marine protected areas.csv")

protected_areas_marine_terrestrial = 
  protected_areas_marine_terrestrial %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area,
         protected_areas_marine_terrestrial_latest_year = latest.year.available, 
         protected_areas_marine_terrestrial = Terrestrial.and.marine.protected.areas....of.total.territorial.area.) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)

## Marine and Coastal Protected areas
# first row is world total
protected_areas_marine_coastal = read.csv("Raw_Data/Marine and Coastal Areas/Marine protected areas.csv")

protected_areas_marine_coastal = 
  protected_areas_marine_coastal %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area,
         protected_areas_marine_latest_year = latest.year.available, 
         protected_areas_marine = Marine.protected.areas....of.territorial.waters.) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)

## Forests Data
# deforestaion and fire areas not included due to 
# significant number of missing values
# row 1 is world total
forest_areas = read.csv("Raw_Data/Forests/Forest Area.csv")

forest_areas = 
  forest_areas %>%
  rename(Country_ID = CountryID,
         Country = Country.and.Area,
         forest_area_2015 = Forest.Area..2015..1000.ha., 
         forest_area_2020 = Forest.Area..2020..1000.ha.,
         forest_total_land_area_2020 = Total.Land.Area..2020..1000.ha.) %>%
  select(Country_ID,Country,forest_area_2015,forest_area_2020,forest_total_land_area_2020) %>%
  slice(2:n()) %>%
  assert(not.missing.p, Country_ID)


## Governance
governance = read.csv("Raw_Data/Governance/Governance.csv")

governance = governance %>%
  rename(Country_ID = CountryID,
         Country = Country.and.area) %>%
  rename_with(~gsub(".", "_", .x, fixed = TRUE)) %>%
  assert(not.missing.p, Country_ID)

# Append all of the Datasets
crosswalk_other = rbind.fill(protected_areas_marine_terrestrial,
                                   protected_areas_marine_coastal,
                                   forest_areas,
                                   governance)

# Create the Crosswalk
crosswalk_other = crosswalk_other %>%
  select(Country_ID, Country) %>%
  distinct()

# Check if there are any Duplicates 
# This would mean that for the air and climate datasets
# there are either repeated countries, IDs, or that
# ID is not unique to country between the datasets
# and Vice versa
dim(crosswalk_other[duplicated(crosswalk_other$Country_ID),])[1] == 0
dim(crosswalk_other[duplicated(crosswalk_other$Country),])[1] == 0

# Combine CSVs
# Start with the Above Created Crosswalk
# And Merge on Each of the Datasets
combined_other = 
  left_join(crosswalk_other,protected_areas_marine_terrestrial, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_other = 
  left_join(combined_other,protected_areas_marine_coastal, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_other = 
  left_join(combined_other,forest_areas, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)
combined_other = 
  left_join(combined_other,governance, by = "Country_ID") %>%
  select(-Country.y) %>%
  rename(Country = Country.x)

# Export Data
save(combined_other, file="Intermediate_Data/005_combined_other.Rdata")
write.csv(combined_other,"Intermediate_Data/005_combined_other.csv", row.names = FALSE)

# Merge in Final Crosswalk to Get Universal ID
combined_other_clean = 
  left_join(final_crosswalk_Country_Only,combined_other, by = "Country") %>%
  filter(!is.na(Country_ID)) %>%
  select(-Country, -Country_ID) %>%
  filter(Country_ID_Final != 999) #Excluded before merging

# Clean Up Environment
remove(crosswalk_other,combined_other,protected_areas_marine_terrestrial, 
       protected_areas_marine_coastal,forest_areas, governance)
```

Combine all Categories Code:

```{r combined_all, class.source = 'fold-hide', echo = TRUE, results='hide'}

# Create Clea Final Data and World Bank Dataset
full_data = final_crosswalk %>%
  filter(Country_ID_Final != 999) %>%
  filter(Country_Final != "Swaziland") %>%
  filter(Country_Final != "Czechia") %>%
  filter(Country_Final != "St. Helena") %>%
  filter(Country_Final != "St. Pierre-Miquelon") %>%
  select(-Country) %>%
  distinct()

# Check if there are any Duplicates 
# This would mean that for the air and climate datasets
# there are either repeated countries, IDs, or that
# ID is not unique to country between the datasets
# and Vice versa
dim(full_data[duplicated(full_data$Country_ID_Final),])[1] == 0
dim(full_data[duplicated(full_data$Country_Final),])[1] == 0

# Create Full Dataset (Excluding 999 Countries)
full_data = left_join(full_data,combined_air_climate_clean, by = "Country_ID_Final")
full_data = left_join(full_data,combined_energy_minerals_clean, by = "Country_ID_Final")
full_data = left_join(full_data,combined_land_agricultural_clean, by = "Country_ID_Final")
full_data = left_join(full_data,combined_natural_disaster_clean, by = "Country_ID_Final")
full_data = left_join(full_data,combined_other_clean, by = "Country_ID_Final")

# Save the Data for Use in the Next File
save(full_data, file="Intermediate_Data/01_full_data.Rdata")
remove(combined_air_climate_clean,combined_energy_minerals_clean,combined_land_agricultural_clean,
       combined_natural_disaster_clean,combined_other_clean,final_crosswalk,final_crosswalk_Country_Only)
```


## Limit the Data

The following code limits the observations and variables based on a number of practical criteria. First, any missing values are replaced with NAs. Non-numeric data is converted to numeric (except for country names). Variables that were originally included from the CSVs as "Notes" are excluded. Additionally, the renewable percentage for 2017 is converted to a percentage (the data is a percentage from the source, not a decimal). 

[NOTE NUMBER OF ROWS AND COLUMNS DROPPED]

```{r additional_data_cleaning, class.source = 'fold-hide', echo = TRUE, results='hide'}
## Load the Data from the 01 File
load(file="Intermediate_Data/01_full_data.Rdata")

## Rename Data
full_data_clean = full_data
remove(full_data)

# Convert ... to NA
full_data_clean = full_data_clean %>%
  mutate(across(.cols = everything(), ~ifelse(.x == "...", NA, .x)))

# Remove Note Columns
full_data_clean = full_data_clean %>%
  select(-World_Bank_Notes,-Other_Notes)

# Convert Variables to Numeric
# Everything besides Country and Country ID should be numeric
#full_data_clean = full_data_clean %>%
#  mutate(across(.cols = everything(), ~ifelse(is.character(.x) == TRUE, as.numeric(.x), .x)))
j = ncol(full_data_clean)
i = c(2:j)
full_data_clean[ , i] = apply(full_data_clean[ , i], 2, function(x) as.numeric(x))

# Convert Renewable Percentage 2017 to an Actual Percentage
full_data_clean$renewable_percent_2017 = 
  full_data_clean$renewable_percent_2017/100
```

Any observations (countries) that don't have percent renewable for 2017 are excluded, since that is what predicted, and there is no reasonable way to interpolate the "solution." 19 countries do not have 2017 renewable percentage.

```{r limit_missing_renewables, echo = TRUE, results='hide'}
## Drop Observations that don't have Renewable Energy Percentage for 2019
# There are 19 Such observations
full_data_clean = full_data_clean %>%
  filter(is.na(renewable_percent_2017) == FALSE)
```


Some of the variables and countries are missing a lot of values: more than is reasonable to interpolate. The selected threshold is if the country is missing more than 50 values. This was chosen after reviewing the dataset, and weighs the importance of retaining data (and not biasing the model too much by removing countries) with the practical consideration that fitting a model for an observation that is over mostly interpolated for its predictors is not particularly useful or intersting and makes modeling more dificult.

```{r remove_sparse_observations}
## Get a count of the number of missings, and remove Countries 
# that have 50 or more missing values. See write up for list of
# countries
full_data_row_remove = full_data_clean %>%
  mutate(row_missings = rowSums(is.na(full_data_clean))) %>%
  filter(row_missings < 50)
```

After removing the observations (countries) without much data, a similar process is applied to columns (predictors). Similar logic applies as above. Variables that are mostly missing will be mostly imputed, reducing the value of the process. 

Per capita variables are not included when the raw total is available (since models will be able to include population). Year variables are not included in modeling, but are available for data tracking in "01_full_data.Rdata". Variables are removed "manually" in this step by inspecting the list of variables and number of missings

```{r limit_to_variables}
# Below is a list of the number of missing values per column. 
# Using this list to determine what variables to keep for the final models
# Uncomment the below code for a table of the columns 
# kable(as.matrix(colSums(is.na(full_data_row_remove))))

# See write up for more information regarding model selection. 
# Generally, per capita variables are excluded if the raw value
# is available, given the population variable is present

# N2O and SO2 are missing for too many values to be included
# percent_land_agricultural_2013 is included since agricultural_area_2013 
# is missing for most values (ideally the latter would be kept since 
# Square kilometers is already included)

# Variables with signicant numbers of missings are dropped
limited_data = full_data_row_remove %>%
  select(c(Country_Final,Country_ID_Final,renewable_percent_2017,X2017_Population_World_Bank,X2017_Land_Area_km_2,X2017_GDP_US_Dollars_World_Bank,
           CH4,CO2,GHG,NOx,energy_supply_petajoules,contribution_renewable_to_electric_production,energy_intensity_2017,energy_supply_2017,mining_value_2017,
           percent_land_agricultural_2013,nitrogen_consumption,phosphate_consumption,potash_consumption,terrestrial_protected_areas,
           protected_areas_marine_terrestrial,forest_area_2015,Basel_Convention,CITES,Convention_on_Biological_Diversity,Kyoto__Protocol,Montreal_Protocol,
           Paris_Agreement,Ramsar_Convention,Rotterdam_Convention,Stockholm_Convention,UN_Convention_on_the_Law_of_the_Sea,
           UN_Convention_to_Combat_Desertification,UN_Framework_Convention_on_Climate_Change,World__Heritage_Convention))

# Save the Data for Use in the Next File
save(limited_data, file="Intermediate_Data/02_limited_data.Rdata")
# Clean Environment
remove(full_data_clean,full_data_row_remove,i,j)
```


# Interpolating Missing Data

[Discussion of this section. Reference textbook section that talks about interpolation]

The goal is to predict each missing value using a linear model of all other observations, where any missings in the fit for the model are substituted with the median (but only for the fitting and prediction stage).

Additionally, contribution_renewable_to_electric_production was removed at this step. It was discovered while modeling the variable was basically the same as  rewable_percentage_2017, and likely is a slightly different version of the same information.

```{r data_interpolation, warning = FALSE}
## Load the Data from the 02 File
load(file="Intermediate_Data/02_limited_data.Rdata")

# Highly Correlated, remove from data
# contribution_renewable_to_electric_production
limited_data = limited_data[,-12]

# Count Number of Missings
# Uncomment code to determine number of missings
# colSums(is.na(limited_data))


# Define Model Data
model_data = limited_data

# Loop Over Each Variable Not in 
for(i in 7:ncol(limited_data)) {

  # Get Vector of Predictors (Column Position in limited_data)
  predictors = c(7:34)
  predictors = predictors[predictors != i]

  # Fit the Linear Model on All Precitors (excluding the)
  # variable that is being interpolated
  # Median Replace Function defined in functions section
  fit = 
    lm(data = limited_data, 
       as.matrix(limited_data[,i]) ~ as.matrix(median_replace(limited_data[,predictors])))
  
  # Predict
  prediction = predict(fit,as.data.frame(median_replace(limited_data[,predictors])))
  
  # No Predictions should be less than 0
  # This is based on the variables included, and
  # may change if more variables are included
  negative_indeces = which(prediction < 0)
  prediction[negative_indeces] = 0
  
  # Replace Data With Interpolated Data
  replace_indeces = which(is.na(model_data[,i]))
  model_data[replace_indeces,i] = prediction[replace_indeces]
}

# Save the Data for Use in the Next File
save(model_data, file="Intermediate_Data/03_model_data.Rdata")
# Clean Environment
remove(fit,i,negative_indeces,
       prediction,predictors,replace_indeces)
```

The interpolation process was found to produce values that replaced the missing values in a reasonable manner. All of the variables were checked to determine none of the interpolated values were outliers compared to the emperical distribution of the observed values for each variable. A histogram of "Ramsar Convention Year" is shown below.

```{r}
# Create a Plot to Compare Data Sets before and After
distr_df = data.frame(Filled = model_data$Ramsar_Convention, 
                      Missing = limited_data$Ramsar_Convention) %>% 
  melt(value.name='y_i')

# Plot
ggplot(distr_df, aes(x = y_i, fill = variable)) +
  geom_histogram(position = "identity",binwidth = 2, alpha = .4) +
  labs(x = "y_i", y = "Frequency", 
       title = "Comparison") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 12))
```

This graph illustrates what occurs after interpolating the missing values in the Ramsar Convention variable. For the missing values, there year is being predicted. The interpolated values are mostly towards the center of the distribution, with some weight towards the higher end (later year) of the distribution.  If a country has not signed the convention, it arguably makes sense they would be interpolated to sign later (since signing later implies less enthusiasm for the convention, as does signing later).

# Exploratory Data Analysis

[Fill In]


# Training and Test Data Set

[Include discussion of training and Test Data Set]

```{r train_test_split}
## Load the Data from the 02 File
load(file="Intermediate_Data/03_model_data.Rdata")
# Set Seed for Reproducibility
set.seed(42)

# training set 80% of original data
train = sample(nrow(model_data), .8*(nrow(model_data)))
x.train = model_data[train, ]
y.train = model_data[train, ]$renewable_percent_2017
# test set remaining 20% of original data
x.test = model_data[-train, ]
y.test = model_data[-train, ]$renewable_percent_2017
```


# Model 1: Regularized Linear Model

[Fill In]


# Model 2: Regularized Beta Regression Model